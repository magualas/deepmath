{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "extraction_pipeline.py\n",
    "\n",
    "by Jeff, Manu and Tanc\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import boto3\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "from botocore.client import ClientError\n",
    "# from smart_open import smart_open\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! printf y\\n | conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'sagemaker-cs281'\n",
    "\n",
    "config = {\n",
    "#     'AWS_ACCESS_KEY_ID':'AKIAR66VYUC6JDOEBIFO',            # Credentials only needed if connecting to a private endpoint\n",
    "#     'AWS_SECRET_ACCESS_KEY':'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',\n",
    "    'AWS_REGION':'us-east-2',                    # Region for the S3 bucket, this is not always needed. Default is us-east-1.\n",
    "    'S3_ENDPOINT':'s3.us-east-2.amazonaws.com',  # The S3 API Endpoint to connect to. This is specified in a HOST:PORT format.\n",
    "    'S3_USE_HTTPS':'1',                        # Whether or not to use HTTPS. Disable with 0.\n",
    "    'S3_VERIFY_SSL':'1',  \n",
    "}\n",
    "\n",
    "os.environ.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s3.Bucket(name='sagemaker-cs281')]\n"
     ]
    }
   ],
   "source": [
    "# test s3\n",
    "s3_r = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    s3_r.meta.client.head_bucket(Bucket=BUCKET_NAME)\n",
    "except ClientError as e:\n",
    "    print(e)\n",
    "    \n",
    "print([x for x in s3_r.buckets.all()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::135202906300:role/sagemaker-user'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read s3 processed csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-cs281\n",
      "CPU times: user 7.47 ms, sys: 0 ns, total: 7.47 ms\n",
      "Wall time: 25.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s3_client = boto3.client('s3') \n",
    "\n",
    "print(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "{'train': {'deephol-data-processed/proofs/human/train/X_train_hyp_1.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_2.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_3.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_4.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_5.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_6.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_7.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_8.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_9.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_10.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_11.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_12.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_13.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_14.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_15.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_16.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_17.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_18.csv': 5027,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_19.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_20.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_21.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_22.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_23.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_24.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_25.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_26.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_27.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_28.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_29.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_30.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_31.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_32.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_33.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_34.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_35.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_36.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_37.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_38.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_39.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_40.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_41.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_42.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_43.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_44.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_45.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_46.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_47.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_48.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_49.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_50.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_51.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_52.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_53.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_54.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_55.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_56.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_57.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_58.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_59.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_60.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_61.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_62.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_63.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_64.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_65.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_66.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_67.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_68.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_69.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_70.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_71.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_72.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_73.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_74.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train/X_train_hyp_75.csv': 5026,\n",
    "  'deephol-data-processed/proofs/human/train_1/X_train_hyp_1.csv': 100},\n",
    " 'valid': {'deephol-data-processed/proofs/human/valid/X_train_hyp_1.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_2.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_3.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_4.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_5.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_6.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_7.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_8.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_9.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_10.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_11.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_12.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_13.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_14.csv': 5203,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_15.csv': 5202,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_16.csv': 5202,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_17.csv': 5202,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_18.csv': 5202,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_19.csv': 5202,\n",
    "  'deephol-data-processed/proofs/human/valid/X_train_hyp_20.csv': 5202}}\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generator' from '/home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/generator.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import generator\n",
    "\n",
    "importlib.reload(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from deephol-data-processed/proofs/human/train/\n",
      "Generating examples from a set of 376968 examples\n",
      "Retrieving data from deephol-data-processed/proofs/human/valid/\n",
      "Generating examples from a set of 104054 examples\n",
      "CPU times: user 2.17 s, sys: 1.64 s, total: 3.81 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#  generators\n",
    "importlib.reload(generator)\n",
    "training_generator = generator.Keras_DataGenerator( dataset='train', w_hyp=False)\n",
    "validation_generator = generator.Keras_DataGenerator(dataset='valid', w_hyp= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 128)         160512    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 434,217\n",
      "Trainable params: 434,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "VOCAB_SIZE = 1254\n",
    "INPUT_LENGTH = 1000\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "# model\n",
    "def build_model(vocab_size, embedding_dim, input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(41, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, INPUT_LENGTH)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1892/5890 [========>.....................] - ETA: 3:57:03 - loss: 2.7202 - acc: 0.1594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        verbose=1,\n",
    "                        use_multiprocessing=True,\n",
    "                        epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "loss_history = history.history['loss']\n",
    "\n",
    "numpy_loss_history = np.array(loss_history)\n",
    "np.savetxt(\"training_logs/loss_history_1st.csv\", numpy_loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full history json\n",
    "with open('training_logs/loss_history_1st.json', 'w') as f:\n",
    "    history_dict = vars(history)\n",
    "    try:\n",
    "        del history_dict['model']\n",
    "    except:\n",
    "        print('no model in vars dict')\n",
    "    json.dump(history_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read history and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read numpy array\n",
    "history_toplot = np.genfromtxt(\"training_logs/loss_history_1st.csv\")\n",
    "\n",
    "# read json dict of vars(history)\n",
    "with open('training_logs/loss_history_1st.json', 'r') as f:\n",
    "    b = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE6lJREFUeJzt3XuQ3eV93/H3xwg7BmEuQRCji2UndmPsDlBvoB4YBwcHg6cU59IUx8HUmURpS2bAxW4w7sWNO01jGpKmtodRDANtwTiNIKZTByMnYEImkVmpcoQkExRxkywbYREL8FXm2z/OT/Xxei/n7J7Vanner5kz+9vn+f5++33Q8Dm/ec7Zs6kqJEnteNFCNyBJOrQMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj80hSS/LMk908z/ydJLjuUPUmjYPDrsJfk0SRvWeg+JqqqC6vq5pnqklSSHzsUPUmDMPilw1iSJQvdg154DH4takl+NcmOJPuS3JnklG48SX43yZNJ9ifZkuT13dzbkmxL8kyS3UneO8PP+C9Jnk7ySJIL+8bvTfIr3fGPJflckq8leSrJJ7vx+7ryLyR5Nsk/na7vbq6SXJ7kYeDhJB9N8jsTerozyXvm/l9QLTL4tWgl+Sngt4BfAF4OPAbc1k2fD7wJeA1wbFfz1W7uBuDXquoY4PXAn03zY84CHgJOBD4M3JAkk9R9CLgbOB5YAfw3gKp6Uzd/WlUtrapPztD3QW/vfvapwM3AO5K8qFv3icBbgFun6VuaksGvxeydwI1VtamqvgW8H3hjktXAd4BjgB8HUlXbq2pPd953gFOTvKyqnq6qTdP8jMeq6g+q6rv0AvjlwMmT1H0HeAVwSlV9s6qmfFF4hr4P+q2q2ldV36iqzwNfA87r5i4B7q2qr0zzM6QpGfxazE6hd7cMQFU9S++ufnlV/RnwEeCjwJNJ1iZ5WVf6c8DbgMe67Zk3TvMzvtx3/a93h0snqfvXQIDPJ9ma5Jdn03dfzRMTzrkZ+KXu+JeA/zHN9aVpGfxazL5E7y4bgCRHAz8M7Aaoqt+vqjfQ2y55DfC+bvyBqroYOAn4Y+AP59pIVX25qn61qk4Bfg342DTv5Jm274OXnHDO/wQuTnIa8Nqub2lWDH4tFkcm+aG+xxLgE8C7k5ye5CXAfwI2VNWjSX4iyVlJjgSeA74JPJ/kxUnemeTYqvoOsB94fq7NJfknSVZ03z5NL7gPXvcrwKv6yqfse6rrV9Uu4AF6d/rrquobc+1Z7TL4tVh8GvhG3+ODVfVZ4N8C64A9wI/S2/8GeBnwB/RC+DF6WynXdnOXAo8m2Q/8c3p77nP1E8CGJM8CdwJXVNXObu6DwM1J/i7JL8zQ93RuBv4+bvNojuIfYpEWhyRvorfl84ryf1zNgXf80iLQbVldAXzc0NdcGfzSYS7Ja4G/o/dW0t9b4Hb0AuBWjyQ1xjt+SWrMYfkBUCeeeGKtXr16oduQpEVj48aNT1XVskFqD8vgX716NePj4wvdhiQtGkkem7mqx60eSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWrMjMGfZGWSe5JsS7I1yRWT1Byb5H8n+UJX8+6+ucuSPNw9Lhv1AiRJw1kyQM0B4Kqq2pTkGGBjkvVVta2v5nJgW1VdlGQZ8FCSW4ClwL8HxoDqzr2zqp4e8TokSQOa8Y6/qvZU1abu+BlgO7B8YhlwTJLQC/t99J4w3gqsr6p9XdivBy4YYf+SpCENtcefZDVwBrBhwtRHgNcCXwK2AFdU1fP0niCe6KvbxQ8+aRy89pok40nG9+7dO0xbkqQhDBz8SZYC64Arq2r/hOm3ApuBU4DTgY8kedkwjVTV2qoaq6qxZcuWDXOqJGkIAwV/kiPphf4tVXX7JCXvBm6vnh3AI8CPA7uBlX11K7oxSdICGeRdPQFuALZX1XVTlD0OnNfVnwz8PWAn8Bng/CTHJzkeOL8bkyQtkEHe1XM2cCmwJcnmbuwaYBVAVV0PfAi4KckWIMBvVNVTAEk+BDzQnfebVbVvhP1LkoY0Y/BX1f30wny6mi/Ru5ufbO5G4MZZdSdJGjl/c1eSGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNWTJTQZKVwH8HTgYKWFtV/3VCzfuAd/Zd87XAsqral+RR4Bngu8CBqhobXfuSpGHNGPzAAeCqqtqU5BhgY5L1VbXtYEFVXQtcC5DkIuA9VbWv7xpvrqqnRtm4JGl2Ztzqqao9VbWpO34G2A4sn+aUdwCfGE17kqRRG2qPP8lq4AxgwxTzRwEXAOv6hgu4O8nGJGumufaaJONJxvfu3TtMW5KkIQwc/EmW0gv0K6tq/xRlFwF/MWGb55yq+gfAhcDlSd402YlVtbaqxqpqbNmyZYO2JUka0kDBn+RIeqF/S1XdPk3pJUzY5qmq3d3XJ4E7gDNn16okaRRmDP4kAW4AtlfVddPUHQv8JPCpvrGjuxeESXI0cD7w4FybliTN3iDv6jkbuBTYkmRzN3YNsAqgqq7vxn4GuLuqnus792Tgjt5zB0uAW6vqrlE0LkmanRmDv6ruBzJA3U3ATRPGdgKnzbI3SdI88Dd3JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGzBj8SVYmuSfJtiRbk1wxSc37kmzuHg8m+W6SE7q5C5I8lGRHkqvnYxGSpMENcsd/ALiqqk4F/iFweZJT+wuq6tqqOr2qTgfeD3yuqvYlOQL4KHAhcCrwjonnSpIOrRmDv6r2VNWm7vgZYDuwfJpT3gF8ojs+E9hRVTur6tvAbcDFc2tZkjQXQ+3xJ1kNnAFsmGL+KOACYF03tBx4oq9kF9M/aUiS5tnAwZ9kKb1Av7Kq9k9RdhHwF1W1b9hGkqxJMp5kfO/evcOeLkka0EDBn+RIeqF/S1XdPk3pJXxvmwdgN7Cy7/sV3dgPqKq1VTVWVWPLli0bpC1J0iwM8q6eADcA26vqumnqjgV+EvhU3/ADwKuTvDLJi+k9Mdw5t5YlSXOxZICas4FLgS1JNndj1wCrAKrq+m7sZ4C7q+q5gydW1YEkvw58BjgCuLGqto6qeUnS8GYM/qq6H8gAdTcBN00y/mng07PoTZI0D/zNXUlqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVmxuBPsjLJPUm2Jdma5Iop6s5Nsrmr+Vzf+KNJtnRz46NsXpI0vCUD1BwArqqqTUmOATYmWV9V2w4WJDkO+BhwQVU9nuSkCdd4c1U9Nbq2JUmzNeMdf1XtqapN3fEzwHZg+YSyXwRur6rHu7onR92oJGk0htrjT7IaOAPYMGHqNcDxSe5NsjHJu/rmCri7G18zzbXXJBlPMr53795h2pIkDWGQrR4AkiwF1gFXVtX+Sa7zBuA84KXAXyb5q6r6G+Ccqtrdbf+sT/LFqrpv4vWrai2wFmBsbKxmtxxJ0kwGuuNPciS90L+lqm6fpGQX8Jmqeq7by78POA2gqnZ3X58E7gDOHEXjkqTZGeRdPQFuALZX1XVTlH0KOCfJkiRHAWcB25Mc3b0gTJKjgfOBB0fTuiRpNgbZ6jkbuBTYkmRzN3YNsAqgqq6vqu1J7gL+Gnge+HhVPZjkVcAdvecOlgC3VtVdo16EJGlwMwZ/Vd0PZIC6a4FrJ4ztpNvykSQdHvzNXUlqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVmxuBPsjLJPUm2Jdma5Iop6s5Nsrmr+Vzf+AVJHkqyI8nVo2xekjS8JQPUHACuqqpNSY4BNiZZX1XbDhYkOQ74GHBBVT2e5KRu/Ajgo8BPA7uAB5Lc2X+uJOnQmvGOv6r2VNWm7vgZYDuwfELZLwK3V9XjXd2T3fiZwI6q2llV3wZuAy4eVfOSpOENtcefZDVwBrBhwtRrgOOT3JtkY5J3dePLgSf66nbxg08aB6+9Jsl4kvG9e/cO05YkaQiDbPUAkGQpsA64sqr2T3KdNwDnAS8F/jLJXw3TSFWtBdYCjI2N1TDnSpIGN1DwJzmSXujfUlW3T1KyC/hqVT0HPJfkPuC0bnxlX90KYPfcWpYkzcUg7+oJcAOwvaqum6LsU8A5SZYkOQo4i95rAQ8Ar07yyiQvBi4B7hxN65Kk2Rjkjv9s4FJgS5LN3dg1wCqAqrq+qrYnuQv4a+B54ONV9SBAkl8HPgMcAdxYVVtHvAZJ0hBSdfhtp4+NjdX4+PhCtyFJi0aSjVU1Nkitv7krSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVmxuBPsjLJPUm2Jdma5IpJas5N8rUkm7vHv+ubezTJlm58fNQLkCQNZ8kANQeAq6pqU5JjgI1J1lfVtgl1f15V/2iKa7y5qp6aU6eSpJGY8Y6/qvZU1abu+BlgO7B8vhuTJM2Pofb4k6wGzgA2TDL9xiRfSPInSV7XN17A3Uk2Jlkz604lSSMxyFYPAEmWAuuAK6tq/4TpTcArqurZJG8D/hh4dTd3TlXtTnISsD7JF6vqvkmuvwZYA7Bq1apZLEWSNIiB7viTHEkv9G+pqtsnzlfV/qp6tjv+NHBkkhO773d3X58E7gDOnOxnVNXaqhqrqrFly5bNajGSpJkN8q6eADcA26vquilqfqSrI8mZ3XW/muTo7gVhkhwNnA88OKrmJUnDG2Sr52zgUmBLks3d2DXAKoCquh74eeBfJDkAfAO4pKoqycnAHd1zwhLg1qq6a8RrkCQNIVW10D38gCR7gccWuo8hnQi09pZV19wG17w4vKKqBtonPyyDfzFKMl5VYwvdx6Hkmtvgml94/MgGSWqMwS9JjTH4R2ftQjewAFxzG1zzC4x7/JLUGO/4JakxBr8kNcbgH0KSE5KsT/Jw9/X4Keou62oeTnLZJPN3JlkUv8E8lzUnOSrJ/0nyxe5vOfznQ9v9cJJckOShJDuSXD3J/EuSfLKb39B9aOHBufd34w8leeuh7Hu2ZrveJD/dfejilu7rTx3q3mdrLv/G3fyqJM8mee+h6nleVJWPAR/Ah4Gru+Orgd+epOYEYGf39fju+Pi++Z8FbgUeXOj1zPeagaPo/S0GgBcDfw5cuNBrmmKdRwB/C7yq6/ULwKkTav4lcH13fAnwye741K7+JcAru+scsdBrmsf1ngGc0h2/Hti90OuZ7zX3zf8R8L+A9y70euby8I5/OBcDN3fHNwNvn6TmrcD6qtpXVU8D64EL4P9/wum/Av7jIeh1VGa95qr6elXdA1BV36b3Ka4rDkHPs3EmsKOqdna93kZv7f36/1v8EXBe9xlVFwO3VdW3quoRYAdTfBjhYWTW662q/1tVX+rGtwIvTfKSQ9L13Mzl35gkbwceobfmRc3gH87JVbWnO/4ycPIkNcuBJ/q+38X3/nDNh4DfAb4+bx2O3lzXDECS44CLgD+djyZHYMY19NdU1QHga8APD3ju4WYu6+33c8CmqvrWPPU5SrNec3fT9hvAfzgEfc67gT+PvxVJPgv8yCRTH+j/pqoqycDvhU1yOvCjVfWeifuGC22+1tx3/SXAJ4Dfr6qds+tSh5vuDy79Nr1P3X2h+yDwu9X7myML3cucGfwTVNVbpppL8pUkL6+qPUleDjw5Sdlu4Ny+71cA9wJvBMaSPErvv/tJSe6tqnNZYPO45oPWAg9X1e+NoN35shtY2ff9im5ssppd3ZPZscBXBzz3cDOX9ZJkBb2/r/Guqvrb+W93JOay5rOAn0/yYeA44Pkk36yqj8x/2/NgoV9kWEwP4Fq+/4XOD09ScwK9fcDju8cjwAkTalazeF7cndOa6b2esQ540UKvZYZ1LqH3ovQr+d4Lf6+bUHM53//C3x92x6/j+1/c3cnh/+LuXNZ7XFf/swu9jkO15gk1H2SRv7i74A0spge9/c0/BR4GPtsXbmPAx/vqfpneC3w7gHdPcp3FFPyzXjO9O6oCtgObu8evLPSaplnr24C/offOjw90Y78J/OPu+IfovaNjB/B54FV9536gO+8hDtN3Lo1qvcC/AZ7r+zfdDJy00OuZ73/jvmss+uD3IxskqTG+q0eSGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMb8P2EqDNYB7+cRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_toplot)\n",
    "plt.title('Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker DEPLOY testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM role\n",
    "ON_SAGEMAKER_NOTEBOOK = True\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = 'arn:aws:iam::135202906300:user/jeff_admin'\n",
    "\n",
    "# config\n",
    "bucket = 'sagemaker-cs281'\n",
    "key = 'deephol-data-processed/proofs/human'   # Path from the bucket's root to the dataset\n",
    "train_instance_type='ml.t2.medium'     # The type of EC2 instance which will be used for training\n",
    "deploy_instance_type='ml.t2.mediume'    # The type of EC2 instance which will be used for deployment\n",
    "n_GPUs = 1\n",
    "hyperparameters={\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"decay\": 1e-6\n",
    "}\n",
    "\n",
    "# data\n",
    "train_input_path = \"s3://{}/{}/train/\".format(bucket, key)\n",
    "validation_input_path = \"s3://{}/{}/valid/\".format(bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "estimator = TensorFlow(\n",
    "      entry_point=os.path.join(os.getcwd(), \"train_and_deploy.py\"),     # Your entry script\n",
    "      role=role,\n",
    "      py_version = 'py3',\n",
    "      framework_version=\"1.12.0\",               # TensorFlow's version\n",
    "      hyperparameters=hyperparameters,\n",
    "#       training_steps=1000,\n",
    "#       evaluation_steps=100,\n",
    "      train_instance_count=n_GPUs,                   # \"The number of GPUs instances to use\"\n",
    "      train_instance_type=train_instance_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'ml.t2.medium' at 'resourceConfig.instanceType' failed to satisfy constraint: Member must satisfy enum value set: [ml.p2.xlarge, ml.m5.4xlarge, ml.m4.16xlarge, ml.p3.16xlarge, ml.m5.large, ml.p2.16xlarge, ml.c4.2xlarge, ml.c5.2xlarge, ml.c4.4xlarge, ml.c5.4xlarge, ml.c4.8xlarge, ml.c5.9xlarge, ml.c5.xlarge, ml.c4.xlarge, ml.c5.18xlarge, ml.p3dn.24xlarge, ml.p3.2xlarge, ml.m5.xlarge, ml.m4.10xlarge, ml.m5.12xlarge, ml.m4.xlarge, ml.m5.24xlarge, ml.m4.2xlarge, ml.p2.8xlarge, ml.m5.2xlarge, ml.p3.8xlarge, ml.m4.4xlarge]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9eeee6c6674d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'ml.t2.medium' at 'resourceConfig.instanceType' failed to satisfy constraint: Member must satisfy enum value set: [ml.p2.xlarge, ml.m5.4xlarge, ml.m4.16xlarge, ml.p3.16xlarge, ml.m5.large, ml.p2.16xlarge, ml.c4.2xlarge, ml.c5.2xlarge, ml.c4.4xlarge, ml.c5.4xlarge, ml.c4.8xlarge, ml.c5.9xlarge, ml.c5.xlarge, ml.c4.xlarge, ml.c5.18xlarge, ml.p3dn.24xlarge, ml.p3.2xlarge, ml.m5.xlarge, ml.m4.10xlarge, ml.m5.12xlarge, ml.m4.xlarge, ml.m5.24xlarge, ml.m4.2xlarge, ml.p2.8xlarge, ml.m5.2xlarge, ml.p3.8xlarge, ml.m4.4xlarge]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training ...\")\n",
    "estimator.fit({'training': train_input_path, 'eval': validation_input_path})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
