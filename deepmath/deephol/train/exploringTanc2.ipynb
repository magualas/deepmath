{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/load_data/pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "Tesor Flow Version: 1.14.0 Ingest File\n",
      "Tesor Flow Version: 1.14.0  Utility File\n",
      "Tesor Flow Version: 1.14.0 Extactor 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "import time\n",
    "import ingestor\n",
    "import extractor2\n",
    "import utils\n",
    "import data\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ingestor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:66: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:71: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:73: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:88: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = data.get_train_dataset(params)\n",
    "parser = data.tristan_parser\n",
    "train_parsed = train_data.map(functools.partial(parser, params=params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_parsed.take(1):\n",
    "#     print(i)\n",
    "# tf.Tensor(376967, shape=(), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/utils.py:20: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/extractor2.py:58: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "CPU times: user 57.8 s, sys: 642 ms, total: 58.4 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set features and labels\n",
    "features = {'goal': [], 'goal_asl': [], 'thms': [], 'thms_hard_negatives': []}\n",
    "labels = {'tac_id': []}\n",
    "\n",
    "# iterate over dataset to extract data into arrays. remove 'take' part to iterate over the entire dataset\n",
    "for raw_record in train_parsed.take(TAKE):\n",
    "    fx, lx = raw_record[0], raw_record[1]\n",
    "    features['goal'].append(fx['goal'])\n",
    "    features['goal_asl'].append(fx['goal_asl'])\n",
    "    features['thms'].append(fx['thms'])\n",
    "    features['thms_hard_negatives'].append(fx['thms_hard_negatives'])\n",
    "    labels['tac_id'].append(lx['tac_id'])\n",
    "\n",
    "# instantiate extractor object\n",
    "ex = extractor2.Extractor(params)\n",
    "\n",
    "# tokenize goals\n",
    "temp = ex.tokenize(features['goal'], ex.vocab_table)\n",
    "#pad all goals to be of length 1000\n",
    "goal_list = []\n",
    "for j in range(len(temp)):\n",
    "        l = len(temp[j])\n",
    "        h = tf.pad(temp[j], [[0, 1000-l]], constant_values=0)\n",
    "        goal_list.append(h)\n",
    "features['goal_ids'] = goal_list\n",
    "\n",
    "# tokenize hypotheses. this requires more work since there may be more than one hypothesis\n",
    "length = len(features['goal'])\n",
    "features['goal_asl_ids'] = []\n",
    "\n",
    "for i in range(length):\n",
    "    temp = ex.tokenize(features['goal_asl'][i], ex.vocab_table)\n",
    "    #pad all hypotheses to be of length 1000\n",
    "    hypo_list = []\n",
    "    for j in range(len(temp)):\n",
    "        l = len(temp[j])\n",
    "        h = tf.pad(temp[j], [[0, 1000-l]], constant_values=0)\n",
    "        hypo_list.append(h)\n",
    "    features['goal_asl_ids'].append(hypo_list)\n",
    "\n",
    "del features['goal']\n",
    "del features['goal_asl']\n",
    "del features['thms']\n",
    "del features['thms_hard_negatives']\n",
    "\n",
    "# FEATURES\n",
    "# 'goal_ids': an array of LENGTH OF DATASET containing arrays which are the tokenized goals of length 1000\n",
    "# below is an example of how to access the entire array as numpy arrays\n",
    "# print(features['goal_ids'][0].numpy())\n",
    "# 'goal_asl_ids': this below is an array of LENGTH OF DATASET containing lists of tokenized hypotheses \n",
    "# where each hypothesis is of length 1000. below is an example of how to access the first hypothesis \n",
    "# from the list of hypotheses corresponding to the first training example\n",
    "# print(features['goal_asl_ids'][0][0].numpy())\n",
    "\n",
    "# LABELS\n",
    "# 'tac_id': array containing tactic ids. below is an example of how to access the first tactic\n",
    "# print(labels['tac_id'][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1153453, shape=(2,), dtype=int32, numpy=array([10000,  1000], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(features['goal_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1153456, shape=(1,), dtype=int32, numpy=array([10000], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(labels['tac_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More succing version of creatig a dataset\n",
    "## Need to understand how to do batching\n",
    "def DataframeCreator():\n",
    "    \n",
    "    #create an array of features\n",
    "    features_array = np.zeros((TAKE,1000))\n",
    "    for i,x in enumerate(features['goal_ids']):\n",
    "        features_array[i] = x\n",
    "    \n",
    "    #create an array of labels\n",
    "    labels_array = np.zeros((TAKE))\n",
    "    for i,x in enumerate(labels['tac_id']):\n",
    "        labels_array[i] = x\n",
    "        \n",
    "    \n",
    "    # put these together in a pandas dataframe\n",
    "    # perhaps not the most efficient thing but allows for correct types \n",
    "    # and quick data analysis\n",
    "    \n",
    "    #not necessary to have col names but since we will also be adding hypothesis this may be necessary \n",
    "    feature_cols = []\n",
    "    for i in range(1000):\n",
    "        feature_cols.append(\"h\" + str(i))\n",
    "        \n",
    "    dataset = pd.DataFrame(features_array, columns= feature_cols)\n",
    "    dataset[\"label\"] = labels_array\n",
    "    \n",
    "    return dataset\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataframeCreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>h9</th>\n",
       "      <th>...</th>\n",
       "      <th>h991</th>\n",
       "      <th>h992</th>\n",
       "      <th>h993</th>\n",
       "      <th>h994</th>\n",
       "      <th>h995</th>\n",
       "      <th>h996</th>\n",
       "      <th>h997</th>\n",
       "      <th>h998</th>\n",
       "      <th>h999</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    h0   h1   h2   h3   h4   h5   h6    h7    h8    h9  ...  h991  h992  h993  \\\n",
       "0  2.0  6.0  9.0  4.0  4.0  4.0  8.0   5.0  12.0   7.0  ...   0.0   0.0   0.0   \n",
       "1  2.0  6.0  6.0  9.0  4.0  8.0  5.0  13.0   4.0   4.0  ...   0.0   0.0   0.0   \n",
       "2  2.0  6.0  6.0  9.0  4.0  5.0  4.0   5.0   7.0  43.0  ...   0.0   0.0   0.0   \n",
       "3  2.0  6.0  9.0  4.0  4.0  5.0  7.0   7.0  40.0  18.0  ...   0.0   0.0   0.0   \n",
       "4  2.0  6.0  9.0  4.0  4.0  4.0  8.0   5.0  15.0   7.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   h994  h995  h996  h997  h998  h999  label  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   34.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   37.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0    5.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0    3.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   26.0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainTestSets(dataset):\n",
    "    '''here features and labels are in one object not sure if that is an issue, \n",
    "followed a tutorial buy may have to split?'''\n",
    "\n",
    "    train, test = train_test_split(dataset, test_size=0.2)\n",
    "    target_train = train.pop(\"label\")\n",
    "    Train = tf.data.Dataset.from_tensor_slices((train.values, target_train.values))\n",
    "    Train2 = Train.shuffle(len(train)).batch(1)\n",
    "    \n",
    "    \n",
    "    target_test = test.pop(\"label\")\n",
    "    Test = tf.data.Dataset.from_tensor_slices((test.values, target_test.values))\n",
    "    Test2 = Test.shuffle(len(test)).batch(1)\n",
    "\n",
    "    return Train2, Test2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_object, test_object = TrainTestSets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((?, 1000), (?,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d35c46f8d1a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'glorot_uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(124, input_shape = (1000,), activation='relu', kernel_initializer = 'glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(256, input_shape = (1000,), activation='relu', kernel_initializer = 'glorot_uniform'),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(41, activation='relu', kernel_initializer = 'glorot_uniform'),\n",
    "    tf.keras.layers.Softmax(-1)\n",
    "  ])\n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2512.9860 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2512.2509 - categorical_accuracy: 0.0615\n",
      "Epoch 3/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2514.4244 - categorical_accuracy: 0.0325\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2510.3200 - categorical_accuracy: 5.0000e-04\n",
      "2000/2000 - 5s - loss: 2502.1167 - categorical_accuracy: 0.0015\n",
      "Epoch 1/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2508.7736 - categorical_accuracy: 0.0036\n",
      "Epoch 2/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2509.9572 - categorical_accuracy: 0.0126\n",
      "Epoch 3/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2510.2582 - categorical_accuracy: 0.0105\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2508.4540 - categorical_accuracy: 0.0526\n",
      "2000/2000 - 5s - loss: 2501.7120 - categorical_accuracy: 0.0015\n",
      "Epoch 1/4\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 2508.6821 - categorical_accuracy: 0.0130\n",
      "Epoch 2/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2508.3491 - categorical_accuracy: 0.0250\n",
      "Epoch 3/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2508.4708 - categorical_accuracy: 0.0955\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 2507.9874 - categorical_accuracy: 0.0471\n",
      "2000/2000 - 5s - loss: 2501.6497 - categorical_accuracy: 0.0015\n",
      "Epoch 1/4\n",
      "2733/8000 [=========>....................] - ETA: 24s - loss: 2509.2510 - categorical_accuracy: 0.0165"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model.fit(train_object, epochs=4)\n",
    "    test_loss, test_acc = model.evaluate(test_object, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# lables = df['label']\n",
    "# plt.hist(lables, bins=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02440099, 0.02439384, 0.02439534, 0.02439257, 0.0243917 ,\n",
       "       0.02439156, 0.02439199, 0.02439313, 0.02439625, 0.02424204,\n",
       "       0.02439204, 0.0243916 , 0.02439112, 0.02439501, 0.02439119,\n",
       "       0.02439912, 0.02439206, 0.02439129, 0.02439151, 0.02439477,\n",
       "       0.02439339, 0.02442904, 0.0243953 , 0.02439228, 0.02439201,\n",
       "       0.02439235, 0.0243923 , 0.02439236, 0.02439203, 0.02439222,\n",
       "       0.02439131, 0.02439211, 0.02439087, 0.02439093, 0.02439181,\n",
       "       0.02439218, 0.02439163, 0.02439233, 0.02439227, 0.02439114,\n",
       "       0.02440105], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(row[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3.], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for row in test_object.take(1):\n",
    "    print(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Dense object at 0x7f97b8052128>, <tensorflow.python.keras.layers.core.Dense object at 0x7f979b5ef208>, <tensorflow.python.keras.layers.core.Dense object at 0x7f979b5ef8d0>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 124)               124124    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 64)                8000      \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 132,124\n",
      "Trainable params: 132,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, 1000). Output shape: (None, 124)\n",
      "Input shape: (None, 124). Output shape: (None, 64)\n",
      "Input shape: (None, 64). Output shape: (None, 64)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(\"Input shape: \"+str(layer.input_shape)+\". Output shape: \"+str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
