{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/load_data/pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "import time\n",
    "import ingestor\n",
    "import extractor2\n",
    "import utils\n",
    "import data\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ingestor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.get_train_dataset(params)\n",
    "parser = data.tristan_parser\n",
    "train_parsed = train_data.map(functools.partial(parser, params=params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_parsed.take(1):\n",
    "#     print(i)\n",
    "# tf.Tensor(376967, shape=(), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.9 s, sys: 641 ms, total: 59.5 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set features and labels\n",
    "features = {'goal': [], 'goal_asl': [], 'thms': [], 'thms_hard_negatives': []}\n",
    "labels = {'tac_id': []}\n",
    "\n",
    "# iterate over dataset to extract data into arrays. remove 'take' part to iterate over the entire dataset\n",
    "for raw_record in train_parsed.take(TAKE):\n",
    "    fx, lx = raw_record[0], raw_record[1]\n",
    "    features['goal'].append(fx['goal'])\n",
    "    features['goal_asl'].append(fx['goal_asl'])\n",
    "    features['thms'].append(fx['thms'])\n",
    "    features['thms_hard_negatives'].append(fx['thms_hard_negatives'])\n",
    "    labels['tac_id'].append(lx['tac_id'])\n",
    "\n",
    "# instantiate extractor object\n",
    "ex = extractor2.Extractor(params)\n",
    "\n",
    "# tokenize goals\n",
    "temp = ex.tokenize(features['goal'], ex.vocab_table)\n",
    "#pad all goals to be of length 1000\n",
    "goal_list = []\n",
    "for j in range(len(temp)):\n",
    "        l = len(temp[j])\n",
    "        h = tf.pad(temp[j], [[0, 1000-l]], constant_values=0)\n",
    "        goal_list.append(h)\n",
    "features['goal_ids'] = goal_list\n",
    "\n",
    "# tokenize hypotheses. this requires more work since there may be more than one hypothesis\n",
    "length = len(features['goal'])\n",
    "features['goal_asl_ids'] = []\n",
    "\n",
    "for i in range(length):\n",
    "    temp = ex.tokenize(features['goal_asl'][i], ex.vocab_table)\n",
    "    #pad all hypotheses to be of length 1000\n",
    "    hypo_list = []\n",
    "    for j in range(len(temp)):\n",
    "        l = len(temp[j])\n",
    "        h = tf.pad(temp[j], [[0, 1000-l]], constant_values=0)\n",
    "        hypo_list.append(h)\n",
    "    features['goal_asl_ids'].append(hypo_list)\n",
    "\n",
    "del features['goal']\n",
    "del features['goal_asl']\n",
    "del features['thms']\n",
    "del features['thms_hard_negatives']\n",
    "\n",
    "# FEATURES\n",
    "# 'goal_ids': an array of LENGTH OF DATASET containing arrays which are the tokenized goals of length 1000\n",
    "# below is an example of how to access the entire array as numpy arrays\n",
    "# print(features['goal_ids'][0].numpy())\n",
    "# 'goal_asl_ids': this below is an array of LENGTH OF DATASET containing lists of tokenized hypotheses \n",
    "# where each hypothesis is of length 1000. below is an example of how to access the first hypothesis \n",
    "# from the list of hypotheses corresponding to the first training example\n",
    "# print(features['goal_asl_ids'][0][0].numpy())\n",
    "\n",
    "# LABELS\n",
    "# 'tac_id': array containing tactic ids. below is an example of how to access the first tactic\n",
    "# print(labels['tac_id'][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1153513, shape=(2,), dtype=int32, numpy=array([10000,  1000], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(features['goal_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1153516, shape=(1,), dtype=int32, numpy=array([10000], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(labels['tac_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More succing version of creatig a dataset\n",
    "## Need to understand how to do batching\n",
    "def DataframeCreator():\n",
    "    \n",
    "    #create an array of features\n",
    "    features_array = np.zeros((TAKE,1000))\n",
    "    for i,x in enumerate(features['goal_ids']):\n",
    "        features_array[i] = x\n",
    "    \n",
    "    #create an array of labels\n",
    "    labels_array = np.zeros((TAKE))\n",
    "    for i,x in enumerate(labels['tac_id']):\n",
    "        labels_array[i] = x\n",
    "        \n",
    "    \n",
    "    # put these together in a pandas dataframe\n",
    "    # perhaps not the most efficient thing but allows for correct types \n",
    "    # and quick data analysis\n",
    "    \n",
    "    #not necessary to have col names but since we will also be adding hypothesis this may be necessary \n",
    "    feature_cols = []\n",
    "    for i in range(1000):\n",
    "        feature_cols.append(\"h\" + str(i))\n",
    "        \n",
    "    dataset = pd.DataFrame(features_array, columns= feature_cols)\n",
    "    dataset[\"label\"] = labels_array\n",
    "    \n",
    "    return dataset\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataframeCreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>h9</th>\n",
       "      <th>...</th>\n",
       "      <th>h991</th>\n",
       "      <th>h992</th>\n",
       "      <th>h993</th>\n",
       "      <th>h994</th>\n",
       "      <th>h995</th>\n",
       "      <th>h996</th>\n",
       "      <th>h997</th>\n",
       "      <th>h998</th>\n",
       "      <th>h999</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.062100</td>\n",
       "      <td>6.791900</td>\n",
       "      <td>10.385900</td>\n",
       "      <td>4.162500</td>\n",
       "      <td>7.329400</td>\n",
       "      <td>6.159900</td>\n",
       "      <td>8.433700</td>\n",
       "      <td>9.727800</td>\n",
       "      <td>21.249800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.744800</td>\n",
       "      <td>1.555500</td>\n",
       "      <td>1.570500</td>\n",
       "      <td>1.480700</td>\n",
       "      <td>1.702100</td>\n",
       "      <td>1.402500</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>1.494100</td>\n",
       "      <td>1.454900</td>\n",
       "      <td>16.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427156</td>\n",
       "      <td>1.314598</td>\n",
       "      <td>18.970777</td>\n",
       "      <td>2.914814</td>\n",
       "      <td>10.792467</td>\n",
       "      <td>9.282271</td>\n",
       "      <td>16.599619</td>\n",
       "      <td>17.868885</td>\n",
       "      <td>24.797941</td>\n",
       "      <td>...</td>\n",
       "      <td>12.080185</td>\n",
       "      <td>11.598732</td>\n",
       "      <td>11.058863</td>\n",
       "      <td>10.666555</td>\n",
       "      <td>15.288215</td>\n",
       "      <td>9.394111</td>\n",
       "      <td>14.311634</td>\n",
       "      <td>9.803182</td>\n",
       "      <td>9.985627</td>\n",
       "      <td>12.425105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>828.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>828.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>606.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            h0            h1            h2            h3            h4  \\\n",
       "count  10000.0  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       2.0      6.062100      6.791900     10.385900      4.162500   \n",
       "std        0.0      0.427156      1.314598     18.970777      2.914814   \n",
       "min        2.0      6.000000      6.000000      4.000000      3.000000   \n",
       "25%        2.0      6.000000      6.000000      4.000000      4.000000   \n",
       "50%        2.0      6.000000      6.000000      9.000000      4.000000   \n",
       "75%        2.0      6.000000      9.000000      9.000000      4.000000   \n",
       "max        2.0      9.000000     18.000000    140.000000    166.000000   \n",
       "\n",
       "                 h5            h6            h7            h8            h9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       7.329400      6.159900      8.433700      9.727800     21.249800   \n",
       "std       10.792467      9.282271     16.599619     17.868885     24.797941   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.000000      4.000000      6.000000      7.000000      8.000000   \n",
       "50%        7.000000      4.000000      7.000000      7.000000     22.000000   \n",
       "75%        7.000000      5.000000      7.000000      7.000000     26.000000   \n",
       "max      420.000000    300.000000    828.000000    728.000000    828.000000   \n",
       "\n",
       "       ...          h991          h992          h993          h994  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...      1.744800      1.555500      1.570500      1.480700   \n",
       "std    ...     12.080185     11.598732     11.058863     10.666555   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...    439.000000    763.000000    607.000000    615.000000   \n",
       "\n",
       "               h995          h996          h997          h998          h999  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       1.702100      1.402500      1.555000      1.494100      1.454900   \n",
       "std       15.288215      9.394111     14.311634      9.803182      9.985627   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      821.000000    606.000000    731.000000    303.000000    569.000000   \n",
       "\n",
       "              label  \n",
       "count  10000.000000  \n",
       "mean      16.457500  \n",
       "std       12.425105  \n",
       "min        0.000000  \n",
       "25%        5.000000  \n",
       "50%       15.000000  \n",
       "75%       27.000000  \n",
       "max       40.000000  \n",
       "\n",
       "[8 rows x 1001 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainTestSets(dataset):\n",
    "    '''here features and labels are in one object not sure if that is an issue, \n",
    "followed a tutorial buy may have to split?'''\n",
    "\n",
    "    train, test = train_test_split(dataset, test_size=0.2)\n",
    "    target_train = train.pop(\"label\")\n",
    "    Train = tf.data.Dataset.from_tensor_slices((train.values, target_train.values))\n",
    "    Train2 = Train.shuffle(len(train)).batch(1)\n",
    "    \n",
    "    \n",
    "    target_test = test.pop(\"label\")\n",
    "    Test = tf.data.Dataset.from_tensor_slices((test.values, target_test.values))\n",
    "    Test2 = Test.shuffle(len(test)).batch(1)\n",
    "\n",
    "    return Train2, Test2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_object, test_object = TrainTestSets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='sigmoid')\n",
    "  ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 7607.3617 - acc: 0.9850\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 7606.1873 - acc: 0.9909\n",
      "2000/2000 - 5s - loss: 7470.0469 - acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "for i in range(1):\n",
    "    model.fit(train_object, epochs=2)\n",
    "    test_loss, test_acc = model.evaluate(test_object, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.450e+02, 1.600e+01, 1.220e+02, 1.443e+03, 8.000e+01, 1.710e+03,\n",
       "        1.000e+00, 2.100e+01, 6.590e+02, 2.000e+00, 7.700e+01, 1.000e+00,\n",
       "        2.100e+01, 5.720e+02, 0.000e+00, 9.110e+02, 4.310e+02, 1.000e+00,\n",
       "        1.000e+00, 4.900e+01, 0.000e+00, 5.000e+00, 4.690e+02, 5.000e+00,\n",
       "        4.350e+02, 9.000e+00, 2.360e+02, 8.600e+01, 3.320e+02, 3.900e+01,\n",
       "        0.000e+00, 2.020e+02, 3.030e+02, 3.900e+01, 8.800e+01, 3.000e+00,\n",
       "        1.800e+01, 1.300e+03, 6.800e+01, 8.500e+01, 1.500e+01]),\n",
       " array([ 0.        ,  0.97560976,  1.95121951,  2.92682927,  3.90243902,\n",
       "         4.87804878,  5.85365854,  6.82926829,  7.80487805,  8.7804878 ,\n",
       "         9.75609756, 10.73170732, 11.70731707, 12.68292683, 13.65853659,\n",
       "        14.63414634, 15.6097561 , 16.58536585, 17.56097561, 18.53658537,\n",
       "        19.51219512, 20.48780488, 21.46341463, 22.43902439, 23.41463415,\n",
       "        24.3902439 , 25.36585366, 26.34146341, 27.31707317, 28.29268293,\n",
       "        29.26829268, 30.24390244, 31.2195122 , 32.19512195, 33.17073171,\n",
       "        34.14634146, 35.12195122, 36.09756098, 37.07317073, 38.04878049,\n",
       "        39.02439024, 40.        ]),\n",
       " <a list of 41 Patch objects>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFDhJREFUeJzt3X2QXfV93/H3p2BwbKfmQRtKJLkrJ4ozxJPY6hqTcepxTIMFeCw6Q1yY1FZdOpqmkDolHVskMyFNhhmctiH2xKGjGAXROBBKnKKJlRAFSJnOlIfF5klghw2WrdUItA4PSeuJCfa3f9yf7Ov1rla7d/felc77NXNnz/md373nu2dm72fP7zylqpAkdc8/GHUBkqTRMAAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI46edQFHM2aNWtqfHx81GVI0nHl4Ycf/mpVjS3Ub1UHwPj4OJOTk6MuQ5KOK0m+fCz9HAKSpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjlrVVwKfiMa3f3beZfuvv3iIlUjqOvcAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOWjAAkuxMcjjJE7Pafy7JF5LsS/Lrfe3XJJlK8sUk7+lr39zappJsX95fQ5K0WMdyJfDNwG8BtxxpSPKTwBbgx6rq60m+r7WfA1wG/Ajw/cCfJ/mh9rZPAj8FTAMPJdldVU8u1y8iSVqcBQOgqu5LMj6r+WeB66vq663P4da+BbittX8pyRRwbls2VVXPACS5rfU1ACRpRJZ6DOCHgH+a5IEk/yvJ21r7WuBAX7/p1jZfuyRpRJZ6M7iTgTOA84C3AbcneeNyFJRkG7AN4A1veMNyfKQkaQ5L3QOYBj5TPQ8C3wTWAAeB9X391rW2+dq/S1XtqKqJqpoYGxtbYnmSpIUsNQD+J/CTAO0g7ynAV4HdwGVJTk2yAdgIPAg8BGxMsiHJKfQOFO8etHhJ0tItOASU5FbgXcCaJNPAtcBOYGc7NfRlYGtVFbAvye30Du6+AlxZVd9on3MVcBdwErCzqvatwO8jSTpGx3IW0OXzLPqX8/S/DrhujvY9wJ5FVSdJWjFeCSxJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHLfWRkJ02vv2z8y7bf/3FQ6xEkpbOPQBJ6qgFAyDJziSH29O/Zi/7hSSVZE2bT5JPJJlK8liSTX19tyZ5ur22Lu+vIUlarGPZA7gZ2Dy7Mcl64ALgK33NF9J7DvBGYBtwY+t7Br1HSb4dOBe4NsnpgxQuSRrMggFQVfcBz8+x6AbgI0D1tW0Bbqme+4HTkpwNvAfYW1XPV9ULwF7mCBVJ0vAs6RhAki3Awap6dNaitcCBvvnp1jZf+1yfvS3JZJLJmZmZpZQnSToGiw6AJK8BfhH45eUvB6pqR1VNVNXE2NjYSqxCksTS9gB+ANgAPJpkP7AO+FySfwQcBNb39V3X2uZrlySNyKIDoKoer6rvq6rxqhqnN5yzqaqeBXYDH2xnA50HvFRVh4C7gAuSnN4O/l7Q2iRJI3Isp4HeCvwf4E1JppNccZTue4BngCngd4B/B1BVzwO/BjzUXr/a2iRJI7LglcBVdfkCy8f7pgu4cp5+O4Gdi6xPkrRCvBJYkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI7ygTCSdBRHewAUHN8PgXIPQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqqGN5IMzOJIeTPNHX9p+TfCHJY0n+KMlpfcuuSTKV5ItJ3tPXvrm1TSXZvvy/iiRpMY5lD+BmYPOstr3Am6vqR4G/BK4BSHIOcBnwI+09v53kpCQnAZ8ELgTOAS5vfSVJI7JgAFTVfcDzs9r+rKpeabP303vIO8AW4Laq+npVfYneoyHPba+pqnqmql4Gbmt9JUkjshzHAP418Cdtei1woG/ZdGubr/27JNmWZDLJ5MzMzDKUJ0may0ABkOSXgFeATy9POVBVO6pqoqomxsbGlutjJUmzLPluoEn+FfBe4Pz2MHiAg8D6vm7rWhtHaZckjcCS9gCSbAY+Aryvqr7Wt2g3cFmSU5NsADYCDwIPARuTbEhyCr0DxbsHK12SNIgF9wCS3Aq8C1iTZBq4lt5ZP6cCe5MA3F9V/7aq9iW5HXiS3tDQlVX1jfY5VwF3AScBO6tq3wr8PpKkY7RgAFTV5XM033SU/tcB183RvgfYs6jqJEkrxiuBJamjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6asEASLIzyeEkT/S1nZFkb5Kn28/TW3uSfCLJVJLHkmzqe8/W1v/pJFtX5teRJB2rY9kDuBnYPKttO3B3VW0E7m7zABfSewzkRmAbcCP0AoPek8TeDpwLXHskNCRJo7FgAFTVfcDzs5q3ALva9C7gkr72W6rnfuC0JGcD7wH2VtXzVfUCsJfvDhVJ0hAt9RjAWVV1qE0/C5zVptcCB/r6Tbe2+dolSSMy8EHgqiqglqEWAJJsSzKZZHJmZma5PlaSNMtSA+C5NrRD+3m4tR8E1vf1W9fa5mv/LlW1o6omqmpibGxsieVJkhay1ADYDRw5k2crcGdf+wfb2UDnAS+1oaK7gAuSnN4O/l7Q2iRJI3LyQh2S3Aq8C1iTZJre2TzXA7cnuQL4MvD+1n0PcBEwBXwN+BBAVT2f5NeAh1q/X62q2QeWJUlDtGAAVNXl8yw6f46+BVw5z+fsBHYuqjpJ0orxSmBJ6igDQJI6ygCQpI4yACSpowwASeqoBc8CkkZhfPtn5122//qLh1iJdOJyD0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6aqAASPIfkuxL8kSSW5O8OsmGJA8kmUryB0lOaX1PbfNTbfn4cvwCkqSlWXIAJFkL/HtgoqreDJwEXAZ8DLihqn4QeAG4or3lCuCF1n5D6ydJGpFBh4BOBr4nycnAa4BDwLuBO9ryXcAlbXpLm6ctPz9JBly/JGmJlhwAVXUQ+C/AV+h98b8EPAy8WFWvtG7TwNo2vRY40N77Sut/5lLXL0kazCBDQKfT+69+A/D9wGuBzYMWlGRbkskkkzMzM4N+nCRpHoMMAf0z4EtVNVNVfw98BngHcFobEgJYBxxs0weB9QBt+euBv579oVW1o6omqmpibGxsgPIkSUczSAB8BTgvyWvaWP75wJPAvcClrc9W4M42vbvN05bfU1U1wPolSQMY5BjAA/QO5n4OeLx91g7go8DVSabojfHf1N5yE3Bma78a2D5A3ZKkAQ30RLCquha4dlbzM8C5c/T9O+CnB1mfJGn5eCWwJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQPdDE6rx/j2z867bP/1Fw+xEknHC/cAJKmjDABJ6qiBAiDJaUnuSPKFJE8l+fEkZyTZm+Tp9vP01jdJPpFkKsljSTYtz68gSVqKQfcAPg78aVX9MPBjwFP0nvR1d1VtBO7m20/+uhDY2F7bgBsHXLckaQBLDoAkrwfeSXvkY1W9XFUvAluAXa3bLuCSNr0FuKV67qf38Pizl1y5JGkgg+wBbABmgN9N8vkkn0ryWuCsqjrU+jwLnNWm1wIH+t4/3dokSSMwSACcDGwCbqyqtwL/j1kPeq+qAmoxH5pkW5LJJJMzMzMDlCdJOppBAmAamK6qB9r8HfQC4bkjQzvt5+G2/CCwvu/961rbd6iqHVU1UVUTY2NjA5QnSTqaJQdAVT0LHEjyptZ0PvAksBvY2tq2Ane26d3AB9vZQOcBL/UNFUmShmzQK4F/Dvh0klOAZ4AP0QuV25NcAXwZeH/ruwe4CJgCvtb6SpJGZKAAqKpHgIk5Fp0/R98CrhxkfTq+HO32FOAtKqRR80pgSeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4a9GZwko7B0e6L5D2RNCruAUhSRxkAktRRBoAkdZTHAKRVzuMHWikDB0CSk4BJ4GBVvTfJBuA24EzgYeADVfVyklOBW4B/Avw18C+qav+g61f3+KAZaXksxxDQh4Gn+uY/BtxQVT8IvABc0dqvAF5o7Te0fpKkERkoAJKsAy4GPtXmA7wbuKN12QVc0qa3tHna8vNbf0nSCAy6B/CbwEeAb7b5M4EXq+qVNj8NrG3Ta4EDAG35S63/d0iyLclkksmZmZkBy5MkzWfJAZDkvcDhqnp4GeuhqnZU1URVTYyNjS3nR0uS+gxyEPgdwPuSXAS8GviHwMeB05Kc3P7LXwccbP0PAuuB6SQnA6+ndzBYkjQCS94DqKprqmpdVY0DlwH3VNXPAPcCl7ZuW4E72/TuNk9bfk9V1VLXL0kazEpcCPZR4OokU/TG+G9q7TcBZ7b2q4HtK7BuSdIxWpYLwarqL4C/aNPPAOfO0efvgJ9ejvVJkgbnrSAkqaMMAEnqKANAkjrKm8FJmpM3oTvxuQcgSR1lAEhSRzkEJGnV8Fbfw+UegCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkd5HYB0AvN2DjqaQZ4JvD7JvUmeTLIvyYdb+xlJ9iZ5uv08vbUnySeSTCV5LMmm5folJEmLN8gQ0CvAL1TVOcB5wJVJzqH3pK+7q2ojcDfffvLXhcDG9toG3DjAuiVJAxrkmcCHqupzbfpvgaeAtcAWYFfrtgu4pE1vAW6pnvvpPTz+7CVXLkkayLIcA0gyDrwVeAA4q6oOtUXPAme16bXAgb63Tbe2Q0jqjIXu96PhGfgsoCSvA/4Q+Pmq+pv+ZVVVQC3y87YlmUwyOTMzM2h5kqR5DBQASV5F78v/01X1mdb83JGhnfbzcGs/CKzve/u61vYdqmpHVU1U1cTY2Ngg5UmSjmKQs4AC3AQ8VVW/0bdoN7C1TW8F7uxr/2A7G+g84KW+oSJJ0pANcgzgHcAHgMeTPNLafhG4Hrg9yRXAl4H3t2V7gIuAKeBrwIcGWLckaUBLDoCq+t9A5ll8/hz9C7hyqeuTJC0vbwUhSR11Qt8KwsvgJWl+7gFIUkcZAJLUUSf0ENAgvFpR0onOPQBJ6igDQJI6ygCQpI7yGIDUUSfacS5P+148A2CZHY9/VP7hSCtjoe+DUf99OQQkSR3lHoAkDeB43Os/wj0ASeoo9wCkPh4PUZcYAJIWbVRBeTwPt6xGQx8CSrI5yReTTCXZPuz1S5J6hroHkOQk4JPATwHTwENJdlfVk8Os43i1Gv/7WY01STo2wx4COheYqqpnAJLcBmwBhh4AfnFJOmJU3wejPuY07ABYCxzom58G3j7kGqQVsdQvkUG+fPxH5ti4neaW3qN6h7Sy5FJgc1X9mzb/AeDtVXVVX59twLY2+ybgiwOscg3w1QHev1Ksa3Gsa3Gsa3FOxLr+cVWNLdRp2HsAB4H1ffPrWtu3VNUOYMdyrCzJZFVNLMdnLSfrWhzrWhzrWpwu1zXss4AeAjYm2ZDkFOAyYPeQa5AkMeQ9gKp6JclVwF3AScDOqto3zBokST1DvxCsqvYAe4a0umUZSloB1rU41rU41rU4na1rqAeBJUmrhzeDk6SOOiEDYLXebiLJ/iSPJ3kkyeSIa9mZ5HCSJ/razkiyN8nT7efpq6SuX0lysG23R5JcNOSa1ie5N8mTSfYl+XBrH+n2Okpdo95er07yYJJHW13/qbVvSPJA+7v8g3YiyGqo6+YkX+rbXm8ZZl199Z2U5PNJ/rjNr/z2qqoT6kXv4PJfAW8ETgEeBc4ZdV2ttv3AmlHX0Wp5J7AJeKKv7deB7W16O/CxVVLXrwD/cYTb6mxgU5v+XuAvgXNGvb2OUteot1eA17XpVwEPAOcBtwOXtfb/BvzsKqnrZuDSUW2vvvquBn4f+OM2v+Lb60TcA/jW7Saq6mXgyO0m1Keq7gOen9W8BdjVpncBlwy1KOata6Sq6lBVfa5N/y3wFL2r2ke6vY5S10hVz/9ts69qrwLeDdzR2kexveara+SSrAMuBj7V5sMQtteJGABz3W5i5H8UTQF/luThdsXzanNWVR1q088CZ42ymFmuSvJYGyIa+tDUEUnGgbfS++9x1WyvWXXBiLdXG854BDgM7KW3V/5iVb3Suozk73J2XVV1ZHtd17bXDUlOHXZdwG8CHwG+2ebPZAjb60QMgNXsJ6pqE3AhcGWSd466oPlUb79zVfx3BNwI/ADwFuAQ8F9HUUSS1wF/CPx8Vf1N/7JRbq856hr59qqqb1TVW+hd7X8u8MPDrmEus+tK8mbgGnr1vQ04A/joMGtK8l7gcFU9PMz1wokZAAvebmJUqupg+3kY+CN6fxiryXNJzgZoPw+PuB4Aquq59of7TeB3GMF2S/Iqel+yn66qz7TmkW+vuepaDdvriKp6EbgX+HHgtCRHrj0a6d9lX12b21BaVdXXgd9l+NvrHcD7kuynN2T9buDjDGF7nYgBsCpvN5HktUm+98g0cAHwxNHfNXS7ga1teitw5whr+ZYjX7LNP2fI262Nx94EPFVVv9G3aKTba766VsH2GktyWpv+HnrP/3iK3hfupa3bKLbXXHV9oS/EQ2+cfajbq6quqap1VTVO7/vqnqr6GYaxvUZ95HslXsBF9M6I+Cvgl0ZdT6vpjfTOSHoU2DfquoBb6Q0P/D298cUr6I073g08Dfw5cMYqqeu/A48Dj9H70j17yDX9BL3hnceAR9rrolFvr6PUNert9aPA59v6nwB+ubW/EXgQmAL+B3DqKqnrnra9ngB+j3am0ChewLv49llAK769vBJYkjrqRBwCkiQdAwNAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpo/4/ccaFNYX3FugAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "lables = df['label']\n",
    "plt.hist(lables, bins=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
