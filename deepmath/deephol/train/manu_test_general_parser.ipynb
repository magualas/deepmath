{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils\n",
    "import data\n",
    "# import ingestor\n",
    "# import extractor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_parser(serialized_example, feature_list, label_list):\n",
    "  \"\"\"Parses a HOL example, keeping requested features and labels.\n",
    "\n",
    "  Args:\n",
    "    serialized_example: A tf.Example for a parameterized tactic application.\n",
    "    feature_list: List of string feature names to parse (subset of features).\n",
    "    label_list: List of string label names to parse (subset of labels).\n",
    "\n",
    "  Returns:\n",
    "    features, labels: dicts with keys of feature_list, label_list respectively.\n",
    "  \"\"\"\n",
    "  example = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      features={\n",
    "          # Subgoal features\n",
    "          # goal: the consequent term of the subgoal as a string.\n",
    "          'goal': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "          # goal_asl: list of hypotheses of the subgoal.\n",
    "          'goal_asl': tf.VarLenFeature(dtype=tf.string),\n",
    "          # Parameterized tactic applied to the subgoal\n",
    "          # tactic: string name of tactic that is applied to this subgoal.\n",
    "          'tactic': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "          # tac_id: integer id of tactic.\n",
    "          'tac_id': tf.FixedLenFeature((), tf.int64, default_value=-1),\n",
    "          # thms: list of tactic arguments of type thm.\n",
    "          'thms': tf.VarLenFeature(dtype=tf.string),\n",
    "          # thms_hard_negatives: list of hard negative theorem parameter\n",
    "          # arguments\n",
    "          'thms_hard_negatives': tf.VarLenFeature(dtype=tf.string),\n",
    "      })\n",
    "\n",
    "  for key in ('goal_asl', 'thms', 'thms_hard_negatives'):\n",
    "    if key in example:\n",
    "      example[key] = tf.sparse_tensor_to_dense(example[key], default_value='')\n",
    "\n",
    "  features = {key: example[key] for key in feature_list}\n",
    "  labels = {key: example[key] for key in label_list}\n",
    "  return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tristan_parser(serialized_example, source, params):\n",
    "  del source  # unused\n",
    "\n",
    "  feature_list = ['goal', 'thms', 'thms_hard_negatives']\n",
    "  label_list = ['tac_id']\n",
    "  features, labels = generic_parser(\n",
    "      serialized_example, feature_list=feature_list, label_list=label_list)\n",
    "  \n",
    "  # thms: flatten\n",
    "  size_of_thms = tf.size(features['thms'])\n",
    "  print(size_of_thms) \n",
    "#   print(tf.shape(tf.cond(size_of_thms > 0, lambda: tf.reshape(features['thms'], [-1,size_of_thms]), lambda: '')))\n",
    "  features['thms'] = _choose_one_theorem_at_random(features['thms'])\n",
    "\n",
    "  # thms_hard_negatives: Shuffle, truncate and then pad with '<NULL>'.\n",
    "  features['thms_hard_negatives'] = _shuffle_and_truncate_hard_negatives(\n",
    "      features['thms_hard_negatives'], params)\n",
    "\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(dataset_fn,\n",
    "                 mode,\n",
    "                 params,\n",
    "                 shuffle=None,\n",
    "                 shuffle_queue=None,\n",
    "                 repeat=None,\n",
    "                 parser=None,\n",
    "                 filt=None):\n",
    "    \n",
    "  if shuffle_queue is None:\n",
    "    shuffle_queue = params.shuffle_queue\n",
    "  if shuffle is None:\n",
    "    shuffle = mode == TRAIN\n",
    "  if repeat is None:\n",
    "    do_repeat = mode == TRAIN\n",
    "  elif not repeat:\n",
    "    repeat = None\n",
    "    do_repeat = False\n",
    "\n",
    "  if parser is None:\n",
    "    tf.logging.info('PASSED IN parser is None')\n",
    "    parser = tristan_parser #pairwise_thm_parser\n",
    "\n",
    "  def input_fn():\n",
    "    \"\"\"Input Function for estimator.\"\"\"\n",
    "    ds = dataset_fn(params)\n",
    "    if params.setdefault('cache', False):\n",
    "      ds = ds.cache()\n",
    "    if repeat is not None:\n",
    "      ds = ds.repeat(repeat)\n",
    "    elif do_repeat:\n",
    "      ds = ds.repeat()\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(shuffle_queue)\n",
    "\n",
    "    ds = ds.map(functools.partial(parser, params=params))\n",
    "\n",
    "    if filt is not None:\n",
    "      ds = ds.filter(filt)\n",
    "\n",
    "    drop = mode == EVAL\n",
    "\n",
    "    ds = ds.batch(params['batch_size'], drop_remainder=drop)\n",
    "    \n",
    "    \n",
    "    return ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
