{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
    "from keras.layers import CuDNNLSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import importlib\n",
    "\n",
    "import utilis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# load numpy array from csv file\n",
    "from numpy import loadtxt\n",
    "# load array\n",
    "X_train = loadtxt('x_train2.csv', delimiter=',')\n",
    "Y_train = loadtxt('y_train2.csv', delimiter=',')\n",
    "# print the array\n",
    "X_train\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 41)\n"
     ]
    }
   ],
   "source": [
    "Y_train\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1254\n",
    "INPUT_LENGTH = 1000\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def build_model(vocab_size, embedding_dim, input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(Bidirectional(CuDNNLSTM(128)))\n",
    "#     model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(41, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 128)         160512    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 435,241\n",
      "Trainable params: 435,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, INPUT_LENGTH)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# optimize for GPU\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "model_GPU = multi_gpu_model(model, gpus= 4)\n",
    "model_GPU.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.5478 - acc: 0.4817 - val_loss: 2.4490 - val_acc: 0.2700\n",
      "Epoch 2/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.6591 - acc: 0.4467 - val_loss: 2.4134 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.5682 - acc: 0.4856 - val_loss: 2.4116 - val_acc: 0.3000\n",
      "Epoch 4/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.5081 - acc: 0.5006 - val_loss: 2.4492 - val_acc: 0.2150\n",
      "Epoch 5/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.5105 - acc: 0.4983 - val_loss: 2.3964 - val_acc: 0.2450\n",
      "Epoch 6/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.4597 - acc: 0.5228 - val_loss: 2.4631 - val_acc: 0.2950\n",
      "Epoch 7/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.4255 - acc: 0.5294 - val_loss: 2.5326 - val_acc: 0.2600\n",
      "Epoch 8/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.3848 - acc: 0.5428 - val_loss: 2.5973 - val_acc: 0.2550\n",
      "Epoch 9/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.3483 - acc: 0.5567 - val_loss: 2.5216 - val_acc: 0.2650\n",
      "Epoch 10/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.3511 - acc: 0.5561 - val_loss: 2.5973 - val_acc: 0.2600\n",
      "Epoch 11/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2876 - acc: 0.5833 - val_loss: 2.6620 - val_acc: 0.2400\n",
      "Epoch 12/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2627 - acc: 0.5800 - val_loss: 2.5967 - val_acc: 0.2550\n",
      "Epoch 13/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2372 - acc: 0.5939 - val_loss: 2.5729 - val_acc: 0.2750\n",
      "Epoch 14/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2215 - acc: 0.6039 - val_loss: 2.6578 - val_acc: 0.2250\n",
      "Epoch 15/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1888 - acc: 0.6117 - val_loss: 2.6641 - val_acc: 0.2650\n",
      "Epoch 16/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1987 - acc: 0.6128 - val_loss: 2.7317 - val_acc: 0.2600\n",
      "Epoch 17/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2062 - acc: 0.6117 - val_loss: 2.7567 - val_acc: 0.2350\n",
      "Epoch 18/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1898 - acc: 0.6039 - val_loss: 2.7262 - val_acc: 0.2400\n",
      "Epoch 19/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1229 - acc: 0.6328 - val_loss: 2.8202 - val_acc: 0.2450\n",
      "Epoch 20/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1195 - acc: 0.6178 - val_loss: 2.7198 - val_acc: 0.2650\n",
      "Epoch 21/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1198 - acc: 0.6306 - val_loss: 2.8837 - val_acc: 0.2400\n",
      "Epoch 22/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0582 - acc: 0.6511 - val_loss: 2.9307 - val_acc: 0.1900\n",
      "Epoch 23/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0194 - acc: 0.6517 - val_loss: 2.8774 - val_acc: 0.2200\n",
      "Epoch 24/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0798 - acc: 0.6317 - val_loss: 2.9607 - val_acc: 0.2150\n",
      "Epoch 25/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0078 - acc: 0.6656 - val_loss: 3.0100 - val_acc: 0.2050\n",
      "Epoch 26/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0133 - acc: 0.6750 - val_loss: 2.9130 - val_acc: 0.2200\n",
      "Epoch 27/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0909 - acc: 0.6244 - val_loss: 3.0107 - val_acc: 0.2050\n",
      "Epoch 28/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.4246 - acc: 0.5411 - val_loss: 2.8290 - val_acc: 0.2050\n",
      "Epoch 29/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2563 - acc: 0.5700 - val_loss: 2.8534 - val_acc: 0.2550\n",
      "Epoch 30/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0763 - acc: 0.6350 - val_loss: 2.8654 - val_acc: 0.2500\n",
      "Epoch 31/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9848 - acc: 0.6656 - val_loss: 2.9331 - val_acc: 0.2450\n",
      "Epoch 32/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9346 - acc: 0.6950 - val_loss: 2.9483 - val_acc: 0.2150\n",
      "Epoch 33/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8709 - acc: 0.7128 - val_loss: 2.9482 - val_acc: 0.2450\n",
      "Epoch 34/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8776 - acc: 0.7167 - val_loss: 2.9837 - val_acc: 0.2300\n",
      "Epoch 35/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8306 - acc: 0.7306 - val_loss: 3.0829 - val_acc: 0.2350\n",
      "Epoch 36/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8479 - acc: 0.7239 - val_loss: 3.1014 - val_acc: 0.2400\n",
      "Epoch 37/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8588 - acc: 0.7083 - val_loss: 3.1467 - val_acc: 0.2150\n",
      "Epoch 38/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8548 - acc: 0.7144 - val_loss: 3.1548 - val_acc: 0.2400\n",
      "Epoch 39/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8205 - acc: 0.7239 - val_loss: 3.0979 - val_acc: 0.2550\n",
      "Epoch 40/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8185 - acc: 0.7328 - val_loss: 3.1943 - val_acc: 0.2500\n",
      "Epoch 41/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9947 - acc: 0.6644 - val_loss: 3.0930 - val_acc: 0.2400\n",
      "Epoch 42/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8721 - acc: 0.7089 - val_loss: 3.0750 - val_acc: 0.2300\n",
      "Epoch 43/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7773 - acc: 0.7428 - val_loss: 3.1385 - val_acc: 0.2300\n",
      "Epoch 44/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8424 - acc: 0.7217 - val_loss: 3.1121 - val_acc: 0.2500\n",
      "Epoch 45/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7798 - acc: 0.7350 - val_loss: 3.2170 - val_acc: 0.2400\n",
      "Epoch 46/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6802 - acc: 0.7778 - val_loss: 3.3135 - val_acc: 0.2200\n",
      "Epoch 47/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6277 - acc: 0.7894 - val_loss: 3.3765 - val_acc: 0.2250\n",
      "Epoch 48/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6228 - acc: 0.7944 - val_loss: 3.3230 - val_acc: 0.2600\n",
      "Epoch 49/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6340 - acc: 0.7911 - val_loss: 3.5043 - val_acc: 0.2450\n",
      "Epoch 50/50\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6763 - acc: 0.7878 - val_loss: 3.4143 - val_acc: 0.2600\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "history = model_GPU.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)\n",
    "# callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_json = model_GPU.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save loss\n",
    "LOSS_FILE_NAME = \"BiLSTM_goals_small_manu_ep1\"\n",
    "utilis.history_saver_bad(history, LOSS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "[1.04413629e-02 2.80173816e-04 1.03286910e-03 8.76937527e-03\n",
      " 1.71356180e-04 1.13787306e-02 6.03483795e-06 4.41065367e-06\n",
      " 6.55875877e-02 9.34809941e-06 9.92909889e-04 6.38116398e-06\n",
      " 8.55467655e-03 2.76544561e-05 1.06773114e-05 5.91152627e-03\n",
      " 6.04268163e-02 1.96593348e-04 1.34555385e-05 1.73397581e-04\n",
      " 9.06704099e-06 6.99635666e-06 3.20220692e-03 9.13570184e-05\n",
      " 3.40959802e-02 1.38694914e-02 1.66026934e-03 3.22664477e-04\n",
      " 9.15775448e-03 7.27174920e-05 2.21225309e-05 3.74296476e-04\n",
      " 7.91369565e-03 1.16799446e-03 1.63717225e-01 3.51800772e-05\n",
      " 1.60687734e-04 5.83686590e-01 5.20045171e-03 1.12384884e-03\n",
      " 1.14099064e-04]\n",
      "37\n",
      "37\n",
      "37\n",
      "3\n",
      "32\n",
      "37\n",
      "24\n",
      "5\n",
      "5\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "example_x = X_train[0]\n",
    "print(np.shape(example_x))\n",
    "temp = model.predict(X_train[0:10])\n",
    "# print(len(temp)), temp\n",
    "print(temp[0])\n",
    "for i in temp:\n",
    "    print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
