{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import time\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesor Flow Version: 1.14.0 Ingest File\n",
      "Tesor Flow Version: 1.14.0  Utility File\n",
      "Tesor Flow Version: 1.14.0 Extactor 2\n"
     ]
    }
   ],
   "source": [
    "# list of things to do:\n",
    "import ingestor\n",
    "import extractor2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_iterator(is_train):\n",
    "    '''\n",
    "    returns a batch\n",
    "    '''\n",
    "    input_fn, params = ingestor.get_input_fn(is_train)\n",
    "    features, labels = input_fn()[0], input_fn()[1]\n",
    "    features, labels = extractor2.Extractor(params).extractor(features, labels)\n",
    "    \n",
    "    goals_X = features['goal_ids']\n",
    "    tacid_y = labels['tac_id']\n",
    "    return goals_X, tacid_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:217: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:PASSED IN parser is None\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:66: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:71: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:73: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:88: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/deepmath/deepmath/deephol/train/data.py:242: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [5], [batch]: [3] [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b6c60d2eabff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ce1cfbc73779>\u001b[0m in \u001b[0;36mmanual_iterator\u001b[0;34m(is_train)\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/deepmath/deepmath/deephol/train/data.py\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \"\"\"\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_saveables_for_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [5], [batch]: [3] [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "train_x, train_y = manual_iterator(True)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:PASSED IN parser is None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(10000), Dimension(1000)]),\n",
       " TensorShape([Dimension(10000)]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x, test_y = manual_iterator(False)\n",
    "test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(train_x, tf.float32)\n",
    "y_train = tf.cast(train_y, tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.cast(test_x, tf.float32)\n",
    "y_test = tf.cast(test_y, tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(500, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(41, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 2.0060 - acc: 0.3976\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9991 - acc: 0.3965\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9877 - acc: 0.3982\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 2.0111 - acc: 0.3985\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9867 - acc: 0.3962\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9921 - acc: 0.3990\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9884 - acc: 0.3971\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 1.9969 - acc: 0.3995\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9881 - acc: 0.3977\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9959 - acc: 0.4033\n",
      "10000/10000 - 0s - loss: 5.7818 - acc: 0.1463\n",
      "1 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9983 - acc: 0.3954\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9819 - acc: 0.3991\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9676 - acc: 0.4035\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9752 - acc: 0.4034\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9952 - acc: 0.4006\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 2.0045 - acc: 0.3982\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 2.0000 - acc: 0.4013\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9802 - acc: 0.3997\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 2.0041 - acc: 0.3970\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9870 - acc: 0.3948\n",
      "10000/10000 - 0s - loss: 5.7582 - acc: 0.1347\n",
      "2 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9800 - acc: 0.3988\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9846 - acc: 0.3983\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9694 - acc: 0.3930\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9676 - acc: 0.3976\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9655 - acc: 0.4013\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9822 - acc: 0.4001\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9986 - acc: 0.3934\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9812 - acc: 0.3962\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9941 - acc: 0.3964\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 1.9902 - acc: 0.4019\n",
      "10000/10000 - 0s - loss: 5.8883 - acc: 0.1443\n",
      "3 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9903 - acc: 0.3950\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9676 - acc: 0.4021\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9971 - acc: 0.3943\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9978 - acc: 0.3984\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 2.0216 - acc: 0.3960\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9918 - acc: 0.3962\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 1.9672 - acc: 0.4076\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9655 - acc: 0.4028\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9760 - acc: 0.4052\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9754 - acc: 0.4017\n",
      "10000/10000 - 0s - loss: 6.0339 - acc: 0.1442\n",
      "4 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9677 - acc: 0.4041\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9636 - acc: 0.4017\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9592 - acc: 0.4033\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9527 - acc: 0.4077\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9659 - acc: 0.4029\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9682 - acc: 0.4040\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 1.9699 - acc: 0.3995\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9891 - acc: 0.3993\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 1.9720 - acc: 0.3976\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 1.9748 - acc: 0.4041\n",
      "10000/10000 - 0s - loss: 5.9698 - acc: 0.1307\n",
      "5 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 1.9778 - acc: 0.4035\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 130us/sample - loss: 1.9707 - acc: 0.3985\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 124us/sample - loss: 1.9797 - acc: 0.3996\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 1.9739 - acc: 0.4022\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9593 - acc: 0.4027\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 1.9783 - acc: 0.4017\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 1.9776 - acc: 0.4015\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 1.9525 - acc: 0.4030\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 1.9456 - acc: 0.4047\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9537 - acc: 0.4050\n",
      "10000/10000 - 0s - loss: 6.1451 - acc: 0.1350\n",
      "6 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 1.9547 - acc: 0.4072\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9648 - acc: 0.4026\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 1.9639 - acc: 0.4036\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 1.9671 - acc: 0.4053\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 1.9497 - acc: 0.4060\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 1.9682 - acc: 0.4046\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 1.9522 - acc: 0.4086\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 1.9150 - acc: 0.4132\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 1.9618 - acc: 0.4078\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 1.9832 - acc: 0.4070\n",
      "10000/10000 - 0s - loss: 6.0968 - acc: 0.1327\n",
      "7 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 1.9461 - acc: 0.4085\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 130us/sample - loss: 1.9642 - acc: 0.4084\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 1.9619 - acc: 0.4072\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 1.9647 - acc: 0.4042\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9752 - acc: 0.4028\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 1.9563 - acc: 0.4063\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 1.9514 - acc: 0.4073\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 1.9351 - acc: 0.4126\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 1.9556 - acc: 0.4069\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 1.9472 - acc: 0.4086\n",
      "10000/10000 - 0s - loss: 6.1961 - acc: 0.1360\n",
      "8 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 123us/sample - loss: 1.9475 - acc: 0.4102\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 1.9282 - acc: 0.4158\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 1.9180 - acc: 0.4139\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9519 - acc: 0.4101\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9247 - acc: 0.4105\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 1.9385 - acc: 0.4071\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9297 - acc: 0.4095\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9325 - acc: 0.4130\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 1.9403 - acc: 0.4115\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 1.9394 - acc: 0.4072\n",
      "10000/10000 - 0s - loss: 6.2364 - acc: 0.1303\n",
      "9 : ------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 1.9377 - acc: 0.4092\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 1.9923 - acc: 0.4027\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 1.9846 - acc: 0.4068\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 2.0071 - acc: 0.4097\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 1.9918 - acc: 0.4088\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 1.9845 - acc: 0.4062\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9754 - acc: 0.4037\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 1.9377 - acc: 0.4077\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 1.9458 - acc: 0.4103\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 1.9590 - acc: 0.4043\n",
      "10000/10000 - 0s - loss: 6.2343 - acc: 0.1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, \": ------------------------------------------------------------------------\")\n",
    "    model.fit(x_train, y_train, epochs=10)\n",
    "    test_loss, test_acc = model.evaluate(test_x,  test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 3.5776 - acc: 0.1484\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
