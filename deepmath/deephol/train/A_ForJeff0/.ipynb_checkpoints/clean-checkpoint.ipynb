{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#python packages pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Activation\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import importlib\n",
    "\n",
    "#custom python scripts\n",
    "import generator\n",
    "\n",
    "import utilis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "You are runnning an instance with 4 GPU's\n"
     ]
    }
   ],
   "source": [
    "# Check that you are running GPU's\n",
    "utilis.GPU_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS SETUP SHOULD BE COMPLETE, we are on <botocore.client.S3 object at 0x7fc8d02b3470>\n"
     ]
    }
   ],
   "source": [
    "utilis.aws_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from deephol-data-processed/proofs/human/train/\n",
      "Generating examples from a set of 376968 examples\n",
      "Retrieving data from deephol-data-processed/proofs/human/valid/\n",
      "Generating examples from a set of 104054 examples\n",
      "CPU times: user 2.41 s, sys: 1.46 s, total: 3.87 s\n",
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#  generators\n",
    "importlib.reload(generator)\n",
    "training_generator = generator.Keras_DataGenerator( dataset='train', w_hyp=True)\n",
    "validation_generator = generator.Keras_DataGenerator(dataset='valid', w_hyp= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3000, 128)         160512    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 3000, 128)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 501,033\n",
      "Trainable params: 501,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "# ARE YOU LOADINNG MODE?\n",
    "VOCAB_SIZE = 1254\n",
    "INPUT_LENGTH = 3000\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "# model\n",
    "def build_model(vocab_size, embedding_dim, input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(Bidirectional(CuDNNLSTM(128)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(41, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, INPUT_LENGTH)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ARE YOU LOADING A MODEL IF YES RUN TEH FOLLOWING LINES \n",
    "# from keras.models import model_from_json\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    "# # REMEMEBER TO COMPILE \n",
    "# loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overwriting model\n",
    "# model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "500/500 [==============================] - 273s 546ms/step - loss: 2.7740 - acc: 0.1516\n",
      "CPU times: user 5min 47s, sys: 17.5 s, total: 6min 5s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#try and make it run until 9 am GMT+1\n",
    "n_epochs = 1\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "#                         validation_data=validation_generator,\n",
    "                        verbose=1,\n",
    "                        use_multiprocessing= False,\n",
    "                        epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# FOR SAVING MODEL\n",
    "model_json = model_GPU.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING_DECIDE_HOW_TO_NAME_LOG\n",
    "#descriptionofmodel_personwhostartsrun\n",
    "#e.g. LSTM_128encoder_etc_tanc\n",
    "LOSS_FILE_NAME = \"forjeff\"\n",
    "\n",
    "#WARNING NUMBER 2 - CURRENTLY EVERYTIME YOU RERUN THE CELLS BELOW THE FILES WITH THOSE NAMES GET WRITTEN OVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED SOME LOGS -- OVERWROTE OLD LOGS -- SOMEONE NEEDS TO FIX THIS\n"
     ]
    }
   ],
   "source": [
    "# save history - WARNING FILE NAME \n",
    "utilis.history_saver_bad(history, LOSS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
